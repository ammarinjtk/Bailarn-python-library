{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from bailarn.pos import POSTagger,constant\n",
    "from bailarn.utils import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Text File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read raw text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokentizer model\n",
    "\n",
    "from bailarn.tokenizer import constant as tokenizer_constant\n",
    "from bailarn.tokenizer.tokenizer import Tokenizer\n",
    "\n",
    "# Create index for character and tag\n",
    "char_index = utils.build_tag_index(tokenizer_constant.CHARACTER_LIST, tokenizer_constant.CHAR_START_INDEX)\n",
    "tag_index = utils.build_tag_index(tokenizer_constant.TAG_LIST, tokenizer_constant.TAG_START_INDEX)\n",
    "\n",
    "tokenizer_model = Tokenizer(char_index, tag_index)\n",
    "\n",
    "def tokenize_func(sentence):\n",
    "    return tokenizer_model.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = utils.TextCollection(corpus_directory=\"./data/sample_BEST2010_I2R/\", tokenize_function=tokenize_func)\n",
    "print(\"Corpus size : {}\\n\".format(texts.count))\n",
    "print(\"Example corpus text : {}\\n\".format(texts.get_content(0)[0:500]))\n",
    "print(\"Tokenized content : {} \\n\".format(texts.get_token_list(0)[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read pre-tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = utils.TextCollection(corpus_directory=\"./data/sample_BEST2010_I2R/\", word_delimiter=\"|\",tag_delimiter=\"/\")\n",
    "print(\"Corpus size : {}\\n\".format(texts.count))\n",
    "print(\"Example corpus text : {}\\n\".format(texts.get_content(0)[0:500]))\n",
    "print(\"Tokenized content : {} \\n\".format(texts.get_token_list(0)[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create word and tag indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Word Indexer from vocabs\n",
    "\n",
    "word_index = utils.build_word_index(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved word index\n",
    "\n",
    "import json\n",
    "\n",
    "with open('./bailarn/pos/pos_word_index.json', 'r') as f:\n",
    "    word_index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./bailarn/pos/pos_word_index.json\", \"w\") as write_file:\n",
    "#     json.dump(word_index, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted((value,key) for (key,value) in word_index.items())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tag index\n",
    "\n",
    "tag_index = utils.build_tag_index(constant.TAG_LIST, start_index=1)\n",
    "tag_index['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform text into input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = utils.build_input(text_collection=texts, \n",
    "                       word_index=word_index, \n",
    "                       tag_index=tag_index, \n",
    "                       sequence_length=constant.SEQUENCE_LENGTH, \n",
    "                       target=\"pos\", \n",
    "                       for_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vs.x[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vs.readable_x[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(vs.y[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vs.readable_y[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new model without pre-train embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default embedding_matrix = None\n",
    "\n",
    "new_pos_model = POSTagger(new_model=True, tag_index=tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos_model.train(vs.x, vs.y, epochs=1, validation_split=0.1, batch_size=64, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_pos_model.predict(vs.x, decode_tag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos_model.predict(vs.x, decode_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos_model.evaluate(vs.x, vs.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos_model.save('./bailarn/pos/models/new_abc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new model with pre-train embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load w2v model\n",
    "\n",
    "from bailarn.word_embedder.word2vec import Word2Vec\n",
    "w2v_model = Word2Vec()\n",
    "\n",
    "embedding_matrix = utils.get_embedding_matrix(word2vec_model=w2v_model, word_index=word_index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = POSTagger(embedding_matrix=embedding_matrix, new_model=True, tag_index=tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(vs.x, vs.y, epochs=1, validation_split=0.1, batch_size=64, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(vs.x, vs.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./bailarn/pos/models/abc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = POSTagger(model_path=\"./bailarn/pos/models/abc.h5\", tag_index=tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(vs.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use default POS model\n",
    "- process on pantip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can manually add text in TextCollection\n",
    "\n",
    "sample_text = \"\"\"แจ้งเตือนดีลลวงโลกของNasambkและshopeeต้องอ่านเพื่อไม่เป็นเหยื่ออัพเดตทางshopeeติดต่อมาครับส่วนระบบ\n",
    "ใครจะถูกผิดผมไม่ทราบได้สิ่งที่ควรทำคือปรับปรุงแก้ไขไม่ว่าจะทางร้านหรือทางShopeeโดยทางshopeeออกโค้ดส่วนลดให้ใหม่\n",
    "และผมได้เครื่องเรียบร้อยขอบคุณการแก้ไขของshopeeส่วนร้านก็อยากให้ปรับปรุงเพราะผมยังคงกังขาทุกอย่างมันดูแปลกๆแจ้งเตือนดีล\n",
    "ของร้านNASAmbkในshopeeตามที่ผมคาดการณ์ไว้ยื้อการส่งของจนหมดเวลาระบบshopeeจะยกเลิกออเดอร์อัตโนมัติผมกดขยายเวลาจัดส่ง\n",
    "ก็ไม่ช่วยอะไรเพราะทางร้านต้นทางไม่กดยอมรับผมได้สั่งซื้อMate00proที่เป็นdealoftheday00,000บาทในวันที่00กพ.\n",
    "ระบบแจ้งให้ส่งของภายในวันที่00กพ.ปรากฎว่าร้านยื้อไม่ส่งของอ้างสารพัดจนหมดเวลาส่งระบบshopeeจึงทำการยกเลิกออเดอร์อัตโนมัติ\n",
    "ไม่ได้ของในราคานั้นมันคือขบวนการหลอกลวงต้มตุ๋นนั่นเองดูรายละเอียดในภาพนะครับช่วงแรกคุยกับร้านอีกช่วงคุยกับshopee\"\"\"\n",
    "\n",
    "texts = utils.TextCollection(\"/\", tokenize_function=tokenize_func)\n",
    "texts.add_text(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = len(texts.get_token_list(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = utils.build_input(text_collection=texts,\n",
    "                        word_index=word_index,\n",
    "                        tag_index=tag_index,\n",
    "                        sequence_length=constant.SEQUENCE_LENGTH, # padding size\n",
    "                        target='pos', for_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.readable_x[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load default model\n",
    "\n",
    "model = POSTagger(tag_index=tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(vs.x).flatten()[:text_length]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
